---
title: "HW3 document"
output: github_document
---

```{r loading library, message=FALSE}
library(tidyverse)
library(p8105.datasets)
```

```{r setting}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
```

##Problem 1

```{r loading dataset}
library(p8105.datasets)
data("instacart")
```
The `instacart` dataset contains `r nrow(instacart)` observations and `n nol(instacart)` variables.
Each row represent one product from the instacart order, which contains other information about the product, product id, name, user id, order number, aisle, department id, department and the purchase related information such as if the item is reordered, order hour of the day, day since prior order, and add to cart order. 

```{r number of aisles, and the aisles are the most items ordered from}
instacart |> 
  group_by(aisle) |> 
  summarize(n_obs = n()) |> 
  arrange (desc(n_obs))
```
There are 134 aisles, and `Fresh vegetables` is the most items customers ordered from.

```{r plotting}
instacart |>
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```
From this plot, fresh vegetables and fresh fruits are the most ordered items.

```{r table showing 3 most popular items}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(
    rank = min_rank(desc(n))) |> 
  filter(rank <= 3) |> 
  arrange(desc(n)) |>
  knitr::kable()
```
From `packaged vegetables fruits`, the 3 most popular items are organic baby spinach, organic rasberries, organic blueberries, and from baking ingredients, light brown sugar, pure baking soda and cane sugar are the 3 most popular items. For dog food care, snack sticks chicken & rice recipe dog treats, organix chicken & brown rice recipe and small dog biscuits are the top 3.

```{r table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream}
instacart |> 
  filter(
    product_name == "Pink Lady Apples"|
    product_name == "Coffee Ice Cream") |> 
  group_by(product_name, order_dow) |> 
  summarize(mean_hour = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = product_name,
    values_from = mean_hour) |> 
  knitr::kable(digits = 2)
```


##Problem 2
```{r loading datasets}
library(p8105.datasets)
data("brfss_smart2010")
```
This dataset contains `r nrow(brfss_smart2010)` observations.

```{r renaming and cleaning for response}
brfss_clean<-
  brfss_smart2010|>
  janitor::clean_names()|>
  filter(
    topic=="Overall Health")|>
  filter(
    response==c("Excellent", "Very good", "Good", "Fair", "Poor"))|>
    arrange(factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

For this step in data cleaning, I organize responses as a factor taking levels ordered from “Poor” to “Excellent, and include only response from Excellent to poor. 

```{r rename location}
brfss_clean =
  brfss_smart2010 |> 
  as_tibble() |> 
  janitor::clean_names() |> 
  rename(
    state = locationabbr,
    county = locationdesc) 
```
This step rename state and city, make it easier to look at the data.

```{r state observed 7 or more locations in 2002}
brfss_state2002 <- brfss_clean |>
  filter(year == "2002") |>
  group_by(state) |>
  summarise(county = n_distinct(county)) |>
  filter(county >= 7)

brfss_state2002$state
```
The above 6 states `r names(brfss_state2002)` were observed at 7 or more locations in 2002.


```{r for 2010}
brfss_state2010 <- brfss_clean |> 
  filter(year == "2010") |> 
  group_by(state) |> 
  summarise(county = n_distinct(county)) |>  
  filter(county >= 7) 

brfss_state2010$state
```
The above 14 states `r names(brfss_state2010)` were observed at 7 or more locations in 2010.


```{r construct a dataset, limit to excellent response}
excellent_data <- brfss_clean |>
  filter(response == "Excellent") |>
  select(year, state, data_value) |>
  group_by(year, state) |>
  summarise(avg_data_value = mean(data_value, na.rm = TRUE) ) |>
  drop_na ()
```

```{r making a spaghetti plot}
ggplot(excellent_data, 
       aes(x = year, y = avg_data_value, group = state, color = state)) +
  geom_line () +
  geom_point () +
  labs(title = "Average Value of 'Excellent' Responses Over Time by State",
       x = "Year",
       y = "Average Value") +
  theme(legend.position="left")
```

This is a plot where each state's line depicts how the average "Excellent" response value changes over the years.

```{r finding the data to making two-panel plot for 2006}
ny_data_2006 <- brfss_clean |>
  filter(state == "NY", year == "2006") |>
  select(year, data_value, response, county)
```
This step filter the main dataset to get data specific to: `Years` 2006 , NY state, Responses ranging from "Poor" to "Excellent"


```{r making the plot for 2006}
plot_NY_2006 = ny_data_2006 |>
  ggplot (aes(x=response, y= data_value)) +
  geom_boxplot() +
  labs(
    x= "response",
    y= "data value",
    title= "Plot of Data Value over Responses in 2006 among NY"
  ) +
  scale_fill_discrete(name = "county") +
  theme_minimal()
plot_NY_2006
```













